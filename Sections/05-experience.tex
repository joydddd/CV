%%%%%%%%%%%%%%%%%%%%%%%%%%%%  Experience  %%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \SubHeadingListStart
     \SubHeading
        {PyTorch group, Meta Inc.}{2024,25}
            % POSITION 1
            {Research Scientist Intern}{}
            \ItemListStart
                % \Item{Project: \underline{\href{https://pytorch.org/blog/flexattention/}{FlexAttention}: The Flexibility of PyTorch with the Performance of FlashAttention}}

                \Item{Contribute to TorchInductor \& Helion DSL. }
                \Item{Develop new techniques in PyTorch compiler with a focus on GPU performance optimization. }      
                \Item{Design GPU programming language for fast, flexible, and easy-to-use ML kernel authoring. }
                \Item{Research new techniques for high-performance distributed GPU communication. } 
                \Item{Engage in the open source community to identify user needs and promote new features. }
            \ItemListEnd

        % COMPANY 1
        \SubHeading
        {NVIDIA}{2022,25}
            % POSITION 1
            {Deep Learning Architect Intern}{}
            \ItemListStart
                \Item{Modeled and analyzed next-gen GPU memory features, including distributed shared memory, asynchronous transaction barrier, and Tensor Memory Accelerator (TMA).}
                \Item{Designed and improved compiler abstractions and programming interfaces for GPU domain-specific languages.}
                \Item{Developed modular framework for CuTe DSL decoupling algorithmic logic from GPU scheduling, enabling flexible kernel composition and ML framework integration.}
            \ItemListEnd
            
    \SubHeadingListEnd